{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOnDWGHu2+EMZw+LsAWJKqn"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Otodom.pl Web Scraping with BeautifulSoup"
      ],
      "metadata": {
        "id": "RtpfSDplJ7Rs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time"
      ],
      "metadata": {
        "id": "z_hpWO-II00K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SYR12V9g18f0"
      },
      "outputs": [],
      "source": [
        "# Title\n",
        "def get_Title(soup):\n",
        "\n",
        "    try:\n",
        "        Title = soup.find(\"h1\", attrs = {\"data-cy\":\"adPageAdTitle\"}).text\n",
        "\n",
        "    except AttributeError:\n",
        "        Title = \"\"\n",
        "\n",
        "    return Title\n",
        "\n",
        "# Price\n",
        "def get_Price(soup):\n",
        "\n",
        "    try:\n",
        "        Price = soup.find(\"strong\", attrs = {\"aria-label\":\"Cena\"}).text\n",
        "\n",
        "    except AttributeError:\n",
        "        Price = \"\"\n",
        "\n",
        "    return Price\n",
        "\n",
        "# Location\n",
        "def get_Location(soup):\n",
        "\n",
        "    try:\n",
        "        Location = soup.find(\"a\", attrs = {\"aria-label\":\"Adres\"}).text\n",
        "\n",
        "    except AttributeError:\n",
        "        Location = \"\"\n",
        "\n",
        "    return Location\n",
        "\n",
        "# Surface\n",
        "def get_Surface(soup):\n",
        "    try:\n",
        "        Surface = soup.find(\"div\", attrs = {\"data-testid\":\"table-value-area\"}).text\n",
        "\n",
        "    except AttributeError:\n",
        "        Surface = \"\"\n",
        "\n",
        "    return Surface\n",
        "\n",
        "# Number_of_Rooms\n",
        "def get_Number_of_Rooms(soup):\n",
        "    try:\n",
        "        Number_of_Rooms = soup.find(\"div\", attrs = {\"data-testid\":\"table-value-rooms_num\"}).text\n",
        "\n",
        "    except AttributeError:\n",
        "        Number_of_Rooms = \"\"\n",
        "\n",
        "    return Number_of_Rooms\n",
        "\n",
        "# Floor\n",
        "def get_Floor(soup):\n",
        "    try:\n",
        "        Floor = soup.find(\"div\", attrs = {\"data-testid\":\"table-value-floor\"}).text\n",
        "\n",
        "    except AttributeError:\n",
        "        Floor = \"\"\n",
        "\n",
        "    return Floor\n",
        "\n",
        "\n",
        "# Finishing_Condition\n",
        "def get_Finishing_Condition(soup):\n",
        "    try:\n",
        "        Finishing_Condition = soup.find(\"div\", attrs = {\"data-testid\":\"table-value-construction_status\"}).text\n",
        "\n",
        "    except AttributeError:\n",
        "        Finishing_Condition = \"\"\n",
        "\n",
        "    return Finishing_Condition\n",
        "\n",
        "\n",
        "# Heating\n",
        "def get_Heating(soup):\n",
        "    try:\n",
        "        Heating = soup.find(\"div\", attrs = {\"data-testid\":\"table-value-heating\"}).text\n",
        "\n",
        "    except AttributeError:\n",
        "        Heating = \"\"\n",
        "\n",
        "    return Heating\n",
        "\n",
        "\n",
        "# Parking_Space\n",
        "def get_Parking_Space(soup):\n",
        "    try:\n",
        "        Parking_Space = soup.find(\"div\", attrs = {\"data-testid\":\"table-value-car\"}).text\n",
        "\n",
        "    except AttributeError:\n",
        "        Parking_Space = \"\"\n",
        "\n",
        "    return Parking_Space\n",
        "\n",
        "# Balcony_Garden_Terrace\n",
        "def get_Balcony_Garden_Terrace(soup):\n",
        "    try:\n",
        "        Balcony_Garden_Terrace = soup.find(\"div\", attrs = {\"data-testid\":\"table-value-outdoor\"}).text\n",
        "\n",
        "    except AttributeError:\n",
        "        Balcony_Garden_Terrace = \"\"\n",
        "\n",
        "    return Balcony_Garden_Terrace\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "\n",
        "    HEADERS = {\n",
        "        'User-Agent': '',\n",
        "        'Accept-Language': 'en-US, en;q=0.5'\n",
        "    }\n",
        "\n",
        "    # Base URL\n",
        "    BASE_URL = \"https://www.otodom.pl/pl/wyniki/sprzedaz/mieszkanie/cala-polska?viewType=listing&page=\"\n",
        "\n",
        "    # Number of pages to scrape\n",
        "    num_pages = 200\n",
        "\n",
        "    # Container to store all data\n",
        "    all_data = []\n",
        "\n",
        "    for page in range(1, num_pages + 1):\n",
        "        URL = BASE_URL + str(page)\n",
        "\n",
        "        # HTTP Request\n",
        "        webpage = requests.get(URL, headers=HEADERS)\n",
        "\n",
        "        # Soup Object containing all data\n",
        "        soup = BeautifulSoup(webpage.content, \"html.parser\")\n",
        "\n",
        "        # Fetch links as List of Tag Objects\n",
        "        links = soup.find_all(\"a\", attrs={'data-cy': 'listing-item-link'})\n",
        "\n",
        "        # Store the links\n",
        "        links_list = [link.get('href') for link in links]\n",
        "\n",
        "        # Loop for extracting product details from each link\n",
        "        for link in links_list:\n",
        "            new_webpage = requests.get(\"https://www.otodom.pl\" + link, headers=HEADERS)\n",
        "            new_soup = BeautifulSoup(new_webpage.content, \"html.parser\")\n",
        "\n",
        "            # Function calls to display all necessary product information\n",
        "            data = {\n",
        "                'Title': get_Title(new_soup),\n",
        "                'Price': get_Price(new_soup),\n",
        "                'Location': get_Location(new_soup),\n",
        "                'Surface': get_Surface(new_soup),\n",
        "                'Number_of_Rooms': get_Number_of_Rooms(new_soup),\n",
        "                'Floor': get_Floor(new_soup),\n",
        "                'Finishing_Condition': get_Finishing_Condition(new_soup),\n",
        "                'Heating': get_Heating(new_soup),\n",
        "                'Parking_Space': get_Parking_Space(new_soup),\n",
        "                'Balcony_Garden_Terrace': get_Balcony_Garden_Terrace(new_soup),\n",
        "                'Link': \"https://www.otodom.pl\" + link\n",
        "            }\n",
        "\n",
        "            all_data.append(data)\n",
        "\n",
        "            # Add a 2-second delay\n",
        "        time.sleep(2)\n",
        "\n",
        "    # Create DataFrame from the collected data\n",
        "    otodom_df = pd.DataFrame(all_data)\n",
        "\n",
        "    # Drop rows with missing titles\n",
        "    otodom_df['Title'].replace('', np.nan, inplace=True)\n",
        "    otodom_df = otodom_df.dropna(subset=['Title'])\n",
        "\n",
        "    # Save the DataFrame to a CSV file\n",
        "    otodom_df.to_csv(\"Otodom_Data.csv\", header=True, index=False)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "CLcdiRdd_BEK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
